Created by Andreas Oven Aalsaunet

Task 1

The syntactic rules are (rules|tag count|rule count| conditional probabilities):
|     Rules      | T | R | P(R|C)|
|S  -> NP VP     | 2 | 2 |   1   |
|NP -> NNP       | 6 | 4 |  2/3  |
|NP -> DT NN     | 6 | 2 |  1/3  |
|VP -> VBD NP PP | 2 | 1 |  1/2  |
|VP -> VBD NP NP | 2 | 1 |  1/2  |
|PP -> P NP      | 1 | 1 |   1   |

The lexical rules are (rules|tag count|rule count| conditional probabilities):
|     Rules      | T | R | P(R|C)|
|NNP -> Frodo    | 4 | 2 |  1/2  |
|NNP -> Sam      | 4 | 2 |  1/2  |
|DT  -> the      | 2 | 2 |   1   |
|NN  -> ring     | 2 | 2 |   1   |
|P   -> to       | 1 | 1 |   1   |
|VBD -> gave     | 2 | 2 |   1   |

Task 3A

TODO: Correct this and include that edges also gets added through the fundamental rule.

When an edge is created it is stored in the agenda where it is later retrieved and
added to the chart. A new edge gets added to the agenda from two places in the parse-function.

I. Initialization 
In the initialization step of the parse-function an edge is created for each
word and category combination of the input sequence. If e.g. the word "flies" appear in the
input sequence, and we use the toy.mrg-file as our grammar, two edges is created from
this word: One representing the word as an plural noun and one representing the the word as a
present verb.

When an edge is a created for a word-category pair at this point in the function, it is given
the following properties:

from i      = Start position of the edge where i is the position of the word
     	      in the input string 
to i+1      = End postion of the edge. Since we are creating edges for individual words at this
       	      point the vertix/substring length is 1, thus end = start + 1
category    = the category of the lexeme struct that was retrieved when calling
	      (get-lexeme word grammar)
daughters   = A list of lexical edges that is passive from the start.
probability = The probability of the lexeme struct that was retrieved when calling
	      (get-lexeme word grammar)

In order for this to happen one condition must be met: The word must appear in the
training data. If no lexeme(s) is returned when calling the get-lexemes with the word
and the grammar struct (that stores the training data), the parse function returns/aborts
and returns nil.

II. Main Parser Loop
In the main loop of the parse-function an edge is created if there are no equivalent
edges in the chart yet. If this occurres the function adds the edge, applies the fundamental
rule and predicts new edges which is also added to the agenda.

When an edge is created at this point in the function, it is given the following properties:
from        = The same from-value as the host edge.
to          = The same to-value as the host edge.
category    = The non-terminal on the left hand side of the rule that is derived from
	      calling the function rules-starting-in with the host edge's
	      category and the current grammar.
daughters   = A list, initially containing the host edge.
unanalyzed  = The non-terminal(s), except the first, on the right hand side of the
	      rule that is derived from calling the function rules-starting-in
	      with the host edge's category and the current grammar
probability = The probability of the rule that is derived from
	      calling the function rules-starting-in with the host edge's
	      category and the current grammar.

As stated above these events are triggered if there are no equivalent edges in the chart.
If there are equivalent edges, these extra "prediciton-edges" is not created.


TASK 4A

The viterbi function's task is to find the most probable parse tree in
our parse forest (alternate trees) and return it. The packed forrest is here represented as
a single edge, which can contained multiple packed alternatives. 

In our implementation the function starts out by checking if the edge, given as a argument to
the function, has values stored in its cache. The catch is a variable in each of the edge
objects that stores results to avoid recalculations (dynamic programming).
If the edge variable is empty (nil) it means that the calculations have yet to be done,
and the function continues. If the cache contains values the rest of the statements in the
function is skipped.

If edge's cache is empty the function next checks if the edge has daughters (i.e. edge's
daughter is not nil). If the edge has no daughters the edge-cache is simply set to point to
the edge itself (to avoid doing this check twice).
If the edge does have daughters, the function goes into a two-level loop,
which both contains recursive calls. 

At the start of the first loop, the probability of the edge is set to itself + the result
of the second level loop. In the second level loop each of the edge's daughters are
iterated through and for each iteration the loop sums the result of calling
"(viterbi daughter)" on each of the egde's daughters (recursive calls). Once the second
level loop has finished the edge's probability is thus the sum of its own probability and all
its daughters probabilites.

The first level loop continues by iterating through all the edge's alternates, which is
other complete trees in the parse forrest, also represented as edges. For each of these
alternates the viterbi-function is called with the alternate edge (recursive calls) and their
probabilities is calculated in the same manner as above. For each of these resulting
probabilities, the loops checks if any of these are higher than the original edge's
probability. If this is the case the edge-probability is set to that probability and the
edge's daughters are replaced with the daughters of the alternate, effectivly replacing
the parse tree with the more probable one (the alternate). When the loops have finished the
edge, which is now the most probable parse tree, is returned.

TASK 4B

Conceptually both our Hidden Markov Model implementation and our Chart Parser implementation
uses viterbi the same way: To continously store calcultations and use these instead of doing
the same calculations several times (dynamic programming), and to keep a record of
backpointers to traverse our model and finding the the most probable path or alternative.
Even though both our programs does this the implementations are different in many ways.
In our implementations of the HMM we used two trellises that was very similar to the
conceptual two dimensional matrices: One that stored the (forward) path probability
(i.e the probability from going from one state to another) and one that stored the
backpointers, which pointed out which cell on the previous row that had the
maximum probability for resulting in the current one (which enable us to find the highest
probability path).

In our chart there are no such trellises, this information is instead saved within the
edge structures themself. Previously calculated information, which in HMM's case was stored
in the (forward) path probability trellis, is in the Chart Parser's case stored within
the relevant edge's cache-variable. Previously calculated most probable edges are thus
stored in this cache-slot. Backpointer information, which in HMM's case was stored in
the backpointer trellis, is stored in the daugters slot of the edge. As
our parser takes a bottom-up approach, and thus finds the lowest elements in the trees
first, and builds the trees "upwards" the daughters points to the edges "below" the
current edge and is thus also a backpointer of sorts.

The columns that stored states in the HMM are in this implementation replaced by list of
alternate edges that is kept in each of the edges. As our HMM implementation did for all
states, this implementation does through the edge struct: It compares the previously
computed max probability of each transition (from one edge to another) and updates the max
when appropriate, in the same way our HMM did with state transitions.

TASK 5A

The intuition of the ParsEval Matric is to measure how much the constituents in the
hypothesis parse trees (i.e the ones our parser produces) look like the constituents
in a hand-labeled, gold-reference parse.
This evalution method then assumes that we have human-labeled, gold-reference parse tree for
each sentence in the test set, which is our case comes from the file "test.mrg".

A given constituent in a hypothesis parse is thus labeled "correct" if there is a
constituent in the reference parse (i.e the gold standard) with the same starting point,
the same ending point and the same non-terminal symbol.

We test this by setting the variable wsj to be a grammar struct by using
"(defparameter wsj (read-grammar "wsj.mrg"))"

When running the evaluator without using the viterbi algoritm (baseline case) with 
"(pcfg-evaluate "test.mrg" wsj :baseline t)" the parse evaluatior outputs the following:
-----------------------------------------------------------------------------------------
1. [8] |No , it was n't Black Monday .| (0.80s) P=0.27 R=0.62
2. [6] |The finger-pointing has already begun .| (0.23s) P=0.23 R=0.55
[......]
269. [6] |Federal Home Loan Mortgage Corp. --| (0.22s) P=0.28 R=0.71
270. [10] |The collateral is being sold by a thrift institution .| (1.54s) P=0.24 R=0.59
== 270 inputs; 0.81% coverage; P=0.29 R=0.50 F1=0.37
0.36666268
-----------------------------------------------------------------------------------------

When running the evaluator with the viterbi algoritm (i.e. the command 
"(pcfg-evaluate "test.mrg" wsj)") the parse evaluatior outputs the following:
-----------------------------------------------------------------------------------------
1. [8] |No , it was n't Black Monday .| (0.66s) P=0.86 R=0.92
2. [6] |The finger-pointing has already begun .| (0.22s) P=0.80 R=0.73
[......]
269. [6] |Federal Home Loan Mortgage Corp. --| (0.20s) P=1.00 R=1.00
270. [10] |The collateral is being sold by a thrift institution .| (1.25s) P=1.00 R=1.00
== 270 inputs; 0.81% coverage; P=0.89 R=0.73 F1=0.80
0.80236727
-----------------------------------------------------------------------------------------

If we look at these output, we can see that the ParsEval gives us the following information:
- Input: The number of trees/sentences that were inputed and evaluated
- Coverage: The percentage of our hypothesis trees that were measured again the gold standard
- Recall (R): The number of hypothesis constituents that were correct compared to the
  	      number of corrent constituents in the gold standard parse.
- Precision (P): The number of hypothesis constituents that were correct compared to the
  	    	 total number of hypothesis constituents.
- F1: Measure that included both recall and precision (equally balanced in F1) with the
      formula F1 = 2PR/(P + R).

As we can see, the viterbi algorithms increases the parser accuracy significantly with
precision going from 29% to 89% (60% increase), recall going from 50% to 73% (23% increase)
and F1 going from 37% to 80% (43% increase).


TASK 5B
When running with maxlength = 9:
-----------------------------------------------------------------------------------------
(time (pcfg-evaluate "test.mrg" wsj :maxlength 9))

== 225 inputs; 0.80% coverage; P=0.89 R=0.73 F1=0.80
Evaluation took:
  78.665 seconds of real time
  69.736000 seconds of total run time (64.876000 user, 4.860000 system)
  [ Run times consist of 14.684 seconds GC time, and 55.052 seconds non-GC time. ]
  88.65% CPU
  188,367,004,371 processor cycles
  5,950,746,784 bytes consed
-----------------------------------------------------------------------------------------

When running with maxlength = 10
-----------------------------------------------------------------------------------------
(time (pcfg-evaluate "test.mrg" wsj :maxlength 10))

== 270 inputs; 0.81% coverage; P=0.89 R=0.73 F1=0.80
Evaluation took:
  141.084 seconds of real time
  124.372000 seconds of total run time (116.180000 user, 8.192000 system)
  [ Run times consist of 28.320 seconds GC time, and 96.052 seconds non-GC time. ]
  88.15% CPU
  337,831,872,668 processor cycles
  10,042,719,840 bytes consed
-----------------------------------------------------------------------------------------

Results:

With a maxlength of 9 words 225 sentences were parsed.
With a maxlength of 10 words 270 sentences were parsed.

With a maxlength of 9 words total run time was 69.7 seconds.
With a maxlength of 10 words total run time was 124.4 seconds.

TASK 5C

A major factor that can affect parsing time is the length of the sentences being analyzed,
and the number of different possible interpretations (structural ambiguities) of each
of the substrings of that sentence. With a naive exhaustive search this grows
exponentially with the length of the sentence.

With dynamic programming algorithms, such as the viterbi algorithm, we can partially
circumvent this problem by storing intermediate calculations and using them instead of
recalculating, which can makes our parser use polynominally more time, instead of
exponentially more time (which is far more favorable).

We could thus minimize the time used during training by using smaller trees with a smaller
sentence length.
